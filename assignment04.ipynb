{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment04.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6bsrbM9RuxzwbLsLcazpC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yAaqIcA9hvy0","colab_type":"text"},"source":["1. Load data"]},{"cell_type":"code","metadata":{"id":"mCjFypiJiAu_","colab_type":"code","colab":{}},"source":["import csv\n","import numpy as np\n","\n","train_x = []\n","train_y = []\n","\n","test_x = []\n","test_y = []\n","\n","with open('data_train.csv', newline='') as myfile:\n","    reader  = csv.reader(myfile, delimiter=',')\n","    ct = 1 \n","    for i in reader:\n","        train_x.append([i[0], i[1], i[2]])\n","        train_y.append([i[3]])\n","        # print('[', ct, ']', 'x =', i[0], ', y = ', i[1], ', z = ', i[2], ', h = ', i[3])\n","        ct += 1\n","\n","with open('data_test.csv', newline='') as myfile:\n","    reader  = csv.reader(myfile, delimiter=',')\n","    ct = 1 \n","    for i in reader:\n","        test_x.append([i[0], i[1], i[2]])\n","        test_y.append([i[3]])\n","        # print('[', ct, ']', 'x =', i[0], ', y = ', i[1], ', z = ', i[2], ', h = ', i[3])\n","        ct += 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZGc4RmTrR2R","colab_type":"text"},"source":["- load then make train, test data set\n","- train_x , test_x $\\in$ $N * R^3$\n","- train_y , test_y $\\in$ $N * R^1$"]},{"cell_type":"code","metadata":{"id":"SjpxHCMNiTMr","colab_type":"code","colab":{}},"source":["train_x = np.asarray(train_x).astype(np.float32)\n","train_y = np.asarray(train_y).astype(np.float32)\n","\n","test_x = np.asarray(test_x).astype(np.float32)\n","train_y = np.asarray(test_y).astype(np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9l1dCW_FpY8","colab_type":"text"},"source":["- convert from array to np.ndarray"]},{"cell_type":"markdown","metadata":{"id":"wPo1sEKhmErE","colab_type":"text"},"source":["2. Linear regression"]},{"cell_type":"code","metadata":{"id":"s4jMs0hcmGRC","colab_type":"code","colab":{}},"source":["def hypothesis(theta_0, theta_1, theta_2, theta_3, X):\n","  \"\"\"\n","  params\n","  if train_x (x, y, z) is input, it returns hypothesis of thetas\n","  theta_0 : scalar \n","  theta_1 : scalar\n","  theta_2 : scalar\n","  theta_3 : scalar\n","  X       : matrix : [300, 3]\n","  return [300, ]\n","  \"\"\"\n","  ret = theta_0 + theta_1 * X[:, 0] + theta_2 * X[:, 1] + theta_3 * X[:, 2] \n","  # print(ret.shape)\n","  return ret "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UioQf6vGmZ0X","colab_type":"text"},"source":["- make linear model which has 3 params and input X which contains x, y, z."]},{"cell_type":"code","metadata":{"id":"BxP6eYbkmkL0","colab_type":"code","colab":{}},"source":["def l2_loss (h_hat, h):\n","  m = len(h) # 300, 1\n","\n","  # print(\"h's shape : \", h.shape) # (300, )\n","  # print(\"h_hat's shape : \", h_hat.shape) # (300, )\n","  \n","  ret = np.sum((h_hat - h)*(h_hat - h)) / (2*m)\n","  return ret"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUTnwAuKnEYm","colab_type":"text"},"source":["- make l2 loss for $h$ and $\\hat{h}$"]},{"cell_type":"code","metadata":{"id":"Fq65MnfvnKZa","colab_type":"code","colab":{}},"source":["def gradient_descent(X, Y, theta_0, theta_1, theta_2, theta_3, learning_rate=1e-7):\n","  \"\"\"\n","  X : [300, 3] ndarray - the train x data\n","  Y : [300, 1] ndarrat - the train y data\n","  \"\"\"\n","\n","  m = len(x)  \n","  \n","  gradient_theta_0 = np.sum(hypothesis(theta_0, theta_1, theta_2, theta_3, X) - Y.squeeze()) / m\n","  gradient_theta_1 = np.sum((hypothesis(theta_0, theta_1, theta_2, theta_3, X) - Y.squeeze()) * X[:, 0]) / m\n","  gradient_theta_2 = np.sum((hypothesis(theta_0, theta_1, theta_2, theta_3, X) - Y.squeeze()) * X[:, 1]) / m\n","  gradient_theta_3 = np.sum((hypothesis(theta_0, theta_1, theta_2, theta_3, X) - Y.squeeze()) * X[:, 2]) / m\n","\n","  # print(\"gd : \", gradient_theta_0)\n","\n","  new_theta_0 = theta_0 - learning_rate * gradient_theta_0\n","  new_theta_1 = theta_1 - learning_rate * gradient_theta_1\n","  new_theta_2 = theta_2 - learning_rate * gradient_theta_2\n","  new_theta_3 = theta_3 - learning_rate * gradient_theta_3\n","\n","  return new_theta_0, new_theta_1, new_theta_2, new_theta_3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-C6Nf2Aqo3zL","colab_type":"text"},"source":["- make gradient descent algorithm for multi variable"]},{"cell_type":"code","metadata":{"id":"yFZd5KaAo-w9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"outputId":"f389959e-47ca-47bf-81cf-b5f3613c10f0","executionInfo":{"status":"error","timestamp":1587025590033,"user_tz":-540,"elapsed":720,"user":{"displayName":"조성민","photoUrl":"","userId":"00315417681750132645"}}},"source":["# initialize thetas arbitrarily\n","theta_0 = 30\n","theta_1 = -220\n","theta_2 = -110\n","theta_3 = -230\n","\n","theta_0_list = []\n","theta_1_list = []\n","theta_2_list = []\n","theta_3_list = []\n","loss_list = []\n","test_loss_list = []\n","\n","# until converge about 1000 steps\n","converge_step = 1000\n","for i in range(converge_step):\n","  h_hat = hypothesis(theta_0, theta_1, theta_2, theta_3, train_x)\n","  loss = l2_loss(train_y[:, 0], h_hat)\n","  loss_list.append(loss)\n","\n","  h_hat_for_test = hypothesis(theta_0, theta_1, theta_2, theta_3, test_x)\n","  loss_for_test = l2_loss(test_y[:, 0], h_hat_for_test)\n","  test_loss_list.append(loss_for_test)\n","\n","  theta_0_list.append(theta_0)\n","  theta_1_list.append(theta_1)\n","  theta_2_list.append(theta_2)\n","  theta_3_list.append(theta_3)\n","  theta_0, theta_1, theta_2, theta_3 = gradient_descent(train_x, train_y, theta_0, theta_1, theta_2, theta_3)\n","  "],"execution_count":162,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-162-3c80dc77acd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mh_hat_for_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mloss_for_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_hat_for_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mtest_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_for_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-159-5d746a47d16a>\u001b[0m in \u001b[0;36mhypothesis\u001b[0;34m(theta_0, theta_1, theta_2, theta_3, X)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta_3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;31m# print(ret.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"]}]},{"cell_type":"markdown","metadata":{"id":"GDWNZIASEFpk","colab_type":"text"},"source":["- initialize thetas arbitrarily and linear regeress for multi-variables\n","- using the gradient descent algorithm\n","- converge step is 1000"]},{"cell_type":"markdown","metadata":{"id":"dhEMj1SqEmw5","colab_type":"text"},"source":["---\n","3. plot the estimated parameters using the training dataset"]},{"cell_type":"code","metadata":{"id":"afCTvkbQv2Gv","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","x_ = np.arange(converge_step)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8FGlnS2rET8I","colab_type":"text"},"source":["- define x_ to plot along with steps"]},{"cell_type":"code","metadata":{"id":"U1vCLleKrHcv","colab_type":"code","colab":{}},"source":["plt.scatter(x_, theta_0_list, c='k')\n","plt.scatter(x_, theta_1_list, c='r')\n","plt.scatter(x_, theta_2_list, c='b')\n","plt.scatter(x_, theta_3_list, c='g')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiYz4kgnEdFn","colab_type":"text"},"source":["- plotting estimated parameters"]},{"cell_type":"markdown","metadata":{"id":"WFhJjaYWEx-Z","colab_type":"text"},"source":["---\n","4.  plot the training error"]},{"cell_type":"code","metadata":{"id":"oUZrJ6sCEhCg","colab_type":"code","colab":{}},"source":["plt.scatter(x_, loss_list, c='b')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ol6-zsoKE64M","colab_type":"text"},"source":["- plot the training error"]},{"cell_type":"markdown","metadata":{"id":"ZJ2GKD91E9gX","colab_type":"text"},"source":["--- \n","5. plot the test error\n"]},{"cell_type":"code","metadata":{"id":"Hu2zyS1pE_5P","colab_type":"code","colab":{}},"source":["plt.scatter(x_, loss_list, c='r')\n","plt.show()"],"execution_count":0,"outputs":[]}]}