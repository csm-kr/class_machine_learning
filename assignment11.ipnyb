{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment11.ipnyb","provenance":[{"file_id":"1mHSTxoPNB45FSNvNcj5BmcJWia_HKXma","timestamp":1591321944527},{"file_id":"1bHNhafqHlIA3AaK0c6fAvfKFQBlNBnod","timestamp":1591081918804},{"file_id":"1Mr5v5OPayPbxpgFqqP9RAOAlAT6AeP9t","timestamp":1590465551420},{"file_id":"1ZOY7WhtpuImqOCq6xH9xb3SKjZpWsjDg","timestamp":1590042024344},{"file_id":"1lHsUCT-169HWJX_gH3AHVWMCPf8_fgp6","timestamp":1589267672437},{"file_id":"1kxLGScNJFdPu0TJjKnYjdBghuA8RpayJ","timestamp":1588227282478},{"file_id":"14sk42Vw2kXkbmmU_DRavxSB79umcYmY-","timestamp":1587433034302}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1QigOnxUepqi0Br-udvPuVkdftLeWwAYP","authorship_tag":"ABX9TyNZD0Yin6M0J9dokRcR7Yp1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Eh-H3h7uYq8L","colab_type":"text"},"source":["Multi-label classification using neural networks with a regularization.\n","---"]},{"cell_type":"markdown","metadata":{"id":"TJv1FZVQW5RH","colab_type":"text"},"source":["*1*. Load text data"]},{"cell_type":"code","metadata":{"id":"z_YmrfjLLpQL","colab_type":"code","outputId":"2d57297e-813d-4d11-e33b-f2dadb776c41","executionInfo":{"status":"ok","timestamp":1592200837331,"user_tz":-540,"elapsed":317754,"user":{"displayName":"조성민","photoUrl":"","userId":"00315417681750132645"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["import numpy as np\n","import re\n","import nltk\n","from sklearn.datasets import load_files\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","import pickle\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","\n","review_data = load_files(r\"drive/My Drive/Colab Notebooks/movie_review\")\n","X, y = review_data.data, review_data.target\n","\n","documents = []\n","\n","stemmer = WordNetLemmatizer()\n","\n","for sen in range(0, len(X)):\n","    # Remove all the special characters\n","    document = re.sub(r'\\W', ' ', str(X[sen]))\n","    \n","    # remove all single characters\n","    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","    \n","    # Remove single characters from the start\n","    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n","    \n","    # Substituting multiple spaces with single space\n","    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","    \n","    # Removing prefixed 'b'\n","    document = re.sub(r'^b\\s+', '', document)\n","    \n","    # Converting to Lowercase\n","    document = document.lower()\n","    \n","    # Lemmatization\n","    document = document.split()\n","    document = [stemmer.lemmatize(word) for word in document]\n","    document = ' '.join(document)\n","    \n","    documents.append(document)\n","\n","vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n","X = vectorizer.fit_transform(documents).toarray()\n","\n","tfidfconverter = TfidfTransformer()\n","X = tfidfconverter.fit_transform(X).toarray()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n","print(X_train)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","A\n"],"name":"stdout"},{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[[0.         0.         0.         ... 0.         0.03211483 0.        ]\n"," [0.         0.         0.         ... 0.         0.08401884 0.        ]\n"," [0.         0.         0.         ... 0.06909913 0.         0.        ]\n"," ...\n"," [0.         0.         0.         ... 0.         0.03917949 0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.05031797 0.         ... 0.         0.03543396 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3RFDhWvEkM87","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"11f19fae-61c6-41fd-e71e-a05aee5c8b6b","executionInfo":{"status":"ok","timestamp":1592203413249,"user_tz":-540,"elapsed":981,"user":{"displayName":"조성민","photoUrl":"","userId":"00315417681750132645"}}},"source":["print(X_train.shape[0])  #(1401, 1500)\n","print(y_train.shape)  #(1401,)\n","print(X_test.shape)   #(601, 1500)\n","print(y_test.shape)   #(601,)\n"],"execution_count":92,"outputs":[{"output_type":"stream","text":["1401\n","(1401,)\n","(601, 1500)\n","(601,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"13aKTkiOnmCq","colab_type":"text"},"source":["---\n","2. networks"]},{"cell_type":"code","metadata":{"id":"mqGVb6SQnoku","colab_type":"code","colab":{}},"source":["def sigmoid_(z):\n","  return 1 / (1 + np.exp(-1 * z))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9f1ZHsHFn4PE","colab_type":"code","colab":{}},"source":["def network_forward(input_x, thetas, biases):\n","  \"\"\"\n","  input_x : a data of 1500, 1 \n","  thetas : list of theta\n","  biases : list of bias\n","  \"\"\"\n","\n","  a = []\n","  num_layer = len(thetas)\n","  a.append(input_x)\n","  a_b = input_x                                     # a before \n","  for theta, bias in zip(thetas, biases):\n","    # print(\"theta's shape : \", theta.shape)      # 512, 784 etc...\n","    # print(\"bias' shape : \", bias.shape)         # 512, 1   etc...\n","    a_b = sigmoid_(np.matmul(theta, a_b) + bias)  # 512, 1 etc...\n","    # print(\"a_before's shape : \", a_b.shape)\n","    a.append(a_b)\n","\n","  # print(\"num of output is \", len(a))\n","  return a"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXRoC8FloPy3","colab_type":"code","colab":{}},"source":["def network_backward(a, x, y, thetas, biases, learning_rate=1e-3, lambda_=5e-4):\n","  \n","  # get the delta\n","  deltas = []\n","  delta_before = a[-1] - y                           # 1, 1\n","  deltas.append(delta_before) \n","  # ------------------------- make reverse delta --------------------------\n","  thetas_r = thetas[::-1] # 6. 5. 4. 3. 2. 1\n","  thetas_r = thetas_r[:-1]# 6, 5, 4, 3, 2\n","\n","  # a                     # 1, 2, 3, 4, 5, 6, 7\n","  a_r = a[::-1]           # 7, 6, 5, 4, 3, 2, 1  \n","  a_r = a_r[1:-1]         # 6, 5, 4, 3, 2\n","\n","  for reverse_theta, reverse_a in zip(thetas_r, a_r):\n","    delta_before = np.matmul(reverse_theta.transpose(), delta_before) * reverse_a * (1-reverse_a)\n","    deltas.append(delta_before)\n","\n","  deltas_r = deltas[::-1]  # 2, 3, 4, 5, 6, 7\n","  new_gds = []\n","\n","  for delta_r, a_ in zip(deltas_r, a):\n","    new_gds.append(delta_r @ a_.transpose())\n","\n","  new_thetas = []\n","  new_biases = []\n","\n","  for new_gd, th, delta_r, bias in zip(new_gds, thetas, deltas_r, biases):\n","    new_thetas.append(th - learning_rate * new_gd + th * lambda_)\n","    new_biases.append(bias - learning_rate * delta_r)\n","\n","  return new_thetas, new_biases"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-FXwy5bsDE-","colab_type":"code","colab":{}},"source":["def criterion(out, y, thetas, biases, lambda_=5e-4):\n","  # out - shape : [1, 1]\n","  # y - shape : [1, 1] \n","  # print(\"out's shape : \", out.shape)\n","  # print(\"y's shape : \", y.shape)\n","\n","  out = out.squeeze(1)  # [1]\n","  y = y.squeeze(1)      # [1]\n","  \n","  l2_term = 0 \n","  for theta, bias in zip(thetas, biases):\n","    l2_term += np.mean(np.square(theta))\n","    l2_term += np.mean(np.square(bias))\n","\n","  if l2_term == 0:\n","    loss = np.mean(-1 * (y * np.log(out) + (1-y) * np.log(1-out)))\n","    return loss\n","\n","  l2_term *= lambda_\n","  l2_term /= 2\n","\n","  loss = np.mean(-1 * (y * np.log(out) + (1-y) * np.log(1-out))) + l2_term\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSF4hhRLmYut","colab_type":"code","colab":{}},"source":["def train_classifier(X_train, y_train):\n","  \"\"\"\n","  make neural network classifier\n","  \"\"\"\n","\n","  lambda_ = 5e-5\n","  learning_rate = 1e-4\n","\n","  # make thetas for networks\n","  th1 = np.random.normal(loc=0.0, scale=0.1, size=(512, 1500))\n","  th2 = np.random.normal(loc=0.0, scale=0.1, size=(256, 512))\n","  th3 = np.random.normal(loc=0.0, scale=0.1, size=(128, 256))\n","  th4 = np.random.normal(loc=0.0, scale=0.1, size=(64, 128))\n","  th5 = np.random.normal(loc=0.0, scale=0.1, size=(1, 64))\n","  thetas = [th1, th2, th3, th4, th5]\n","\n","  bias1 = np.random.normal(loc=0.0, scale=0.1, size=(512, 1))\n","  bias2 = np.random.normal(loc=0.0, scale=0.1, size=(256, 1))\n","  bias3 = np.random.normal(loc=0.0, scale=0.1, size=(128, 1))\n","  bias4 = np.random.normal(loc=0.0, scale=0.1, size=(64, 1))\n","  bias5 = np.random.normal(loc=0.0, scale=0.1, size=(1, 1))\n","  biases = [bias1, bias2, bias3, bias4, bias5]  \n","\n","  epochs = 10\n","  print(X_train.shape)\n","  print(y_train.shape)\n","  print(\"epochs : {}\".format(epochs))\n","  loss_list_for_train = []\n","\n","  for epoch in range(epochs):\n","    print('epoch :', epoch)\n","\n","    sum_loss = 0\n","    for idx, (x, y) in enumerate(zip(X_train, y_train)):\n","      \n","      num_data = X_train.shape[0]\n","      if idx == num_data - 1:\n","        mean_loss = sum_loss / (num_data - 1)\n","        print(mean_loss)\n","        loss_list_for_train.append(mean_loss)\n","\n","      y = np.expand_dims(y, axis=0)  # () --> (1,)\n","      # print(x.shape)  (1500, )\n","      # print(y.shape)  (1, )\n","\n","      \n","      x = np.expand_dims(x, axis=1) # 1500 --> 1500, 1\n","      y = np.expand_dims(y, axis=1) # 1 --> 1, 1\n","      a_output = network_forward(x, thetas, biases)\n","      out = a_output[-1]\n","      \n","      # match_cnt += is_same(out, label)\n","      loss = criterion(out, y, thetas, biases, lambda_=lambda_)\n","\n","      # print(loss)\n","      sum_loss += loss \n","      thetas, biases = network_backward(a_output, x, y, thetas, biases, learning_rate, lambda_)\n","\n","  return loss_list_for_train\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5_ETF3ymu5M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":918},"outputId":"99b5f75c-e76e-4232-99a8-3d935daa3924","executionInfo":{"status":"ok","timestamp":1592204085959,"user_tz":-540,"elapsed":225296,"user":{"displayName":"조성민","photoUrl":"","userId":"00315417681750132645"}}},"source":["loss_list_for_train = train_classifier(X_train, y_train)\n","\n","import matplotlib.pyplot as plt\n","\n","ax = plt.figure().gca()\n","# ax.set_xticks(np.arange(epoch + 1))\n","plt.plot(loss_list_for_train, c='b')\n","plt.legend(['training loss'])\n","\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.show()"],"execution_count":106,"outputs":[{"output_type":"stream","text":["(1401, 1500)\n","(1401,)\n","epochs : 10\n","epoch : 0\n","0\n","700\n","0.6959729224082691\n","1400\n","epoch : 1\n","0\n","700\n","0.6953048818041987\n","1400\n","epoch : 2\n","0\n","700\n","0.6953520399846077\n","1400\n","epoch : 3\n","0\n","700\n","0.6954042267936869\n","1400\n","epoch : 4\n","0\n","700\n","0.6954605594670219\n","1400\n","epoch : 5\n","0\n","700\n","0.6955197069917451\n","1400\n","epoch : 6\n","0\n","700\n","0.6955791949148257\n","1400\n","epoch : 7\n","0\n","700\n","0.6956349121788701\n","1400\n","epoch : 8\n","0\n","700\n","0.6956805176327229\n","1400\n","epoch : 9\n","0\n","700\n","0.695706779736779\n","1400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_cr7ctdtfEJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"487dd646-ea9d-4a9e-ddc1-783e9bd79e92","executionInfo":{"status":"ok","timestamp":1592204116592,"user_tz":-540,"elapsed":1023,"user":{"displayName":"조성민","photoUrl":"","userId":"00315417681750132645"}}},"source":["import matplotlib.pyplot as plt\n","\n","ax = plt.figure().gca()\n","# ax.set_xticks(np.arange(epoch + 1))\n","plt.plot(loss_list_for_train, c='b')\n","plt.legend(['training loss'])\n","\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.show()"],"execution_count":107,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ZPDm2rL0I6GP","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","file_data   = \"mnist.csv\"\n","handle_file = open(file_data, \"r\")\n","data        = handle_file.readlines()\n","handle_file.close()\n","\n","size_row    = 28    # height of the image\n","size_col    = 28    # width of the image\n","\n","num_image   = len(data)\n","count       = 0     # count for the number of images\n","print(num_image)    # num_image is 10000.\n","\n","\n","#\n","# normalize the values of the input data to be [0, 1]\n","#\n","def normalize(data):\n","\n","    data_normalized = (data - min(data)) / (max(data) - min(data))\n","\n","    return(data_normalized)\n","\n","#\n","# example of distance function between two vectors x and y\n","#\n","def distance(x, y):\n","\n","    d = (x - y) ** 2\n","    s = np.sum(d)\n","    # r = np.sqrt(s)\n","\n","    return(s)\n","\n","#\n","# make a matrix each column of which represents an images in a vector form\n","#\n","list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n","list_label  = np.empty(num_image, dtype=int)\n","\n","for line in data:\n","\n","    line_data   = line.split(',')\n","    label       = line_data[0]\n","    im_vector   = np.asfarray(line_data[1:])\n","    im_vector   = normalize(im_vector)\n","\n","    list_label[count]       = label\n","    list_image[:, count]    = im_vector\n","\n","    count += 1\n","\n","#\n","# plot first 150 images out of 10,000 with their labels\n","#\n","f1 = plt.figure(1)\n","\n","for i in range(150):\n","\n","    label       = list_label[i]\n","    im_vector   = list_image[:, i]\n","    im_matrix   = im_vector.reshape((size_row, size_col))\n","\n","    plt.subplot(10, 15, i+1)\n","    plt.title(label)\n","    plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","\n","#plt.show()\n","\n","#\n","# plot the average image of all the images for each digit\n","#\n","f2 = plt.figure(2)\n","\n","im_average  = np.zeros((size_row * size_col, 10), dtype=float)\n","im_count    = np.zeros(10, dtype=int)\n","\n","for i in range(num_image):\n","\n","    im_average[:, list_label[i]] += list_image[:, i]\n","    im_count[list_label[i]] += 1\n","\n","for i in range(10):\n","\n","    im_average[:, i] /= im_count[i]\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(i)\n","    plt.imshow(im_average[:,i].reshape((size_row, size_col)), cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPo20R-uSEYE","colab_type":"text"},"source":["- load the data file ('mnist.csv')\n","- each row contains label is digit $l \\in [0, 9]$ and 28 by 28 image pixel values $x \\in R^{784}$"]},{"cell_type":"code","metadata":{"id":"cv63DD8gSCT2","colab_type":"code","colab":{}},"source":["print(list_image.shape)\n","\n","# list_image = list_image.transpose()\n","# list_label = list_label.transpose()\n","\n","# # convert label_to_one_hot\n","print(list_label.shape)  # 10000, \n","num = np.unique(list_label, axis=0)\n","num = num.shape[0]\n","list_label = np.eye(num)[list_label] # \n","list_label = list_label.transpose()  # 10, 10000\n","\n","train_image = list_image[:, :1000]\n","train_label = list_label[:, :1000]\n","test_image = list_image[:, 1000:]\n","test_label = list_label[:, 1000:]\n","\n","print(train_image.shape)  # (784, 1000)\n","print(train_label.shape)  # (10, 1000)\n","\n","print(test_image.shape)   # (784, 9000)\n","print(test_label.shape)   # (10, 9000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QI8W7pt2T3hs","colab_type":"text"},"source":["- consider first 1000 images for training and rest 9000 images for testing.\n","- normalized the image data whose ranges from 0 to 1.\n","- convert label to one-hot encoding label"]},{"cell_type":"markdown","metadata":{"id":"RGKX-MJ6Y4Kj","colab_type":"text"},"source":["---\n","2. neural network architecture\n"]},{"cell_type":"code","metadata":{"id":"0qko7X-50jnh","colab_type":"code","colab":{}},"source":["def sigmoid_(z):\n","  return 1 / (1 + np.exp(-1 * z))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sm6ZUmlGnJfz","colab_type":"text"},"source":["- make sigmoid function for activation."]},{"cell_type":"code","metadata":{"id":"mgF2ZBUKYXai","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def network_forward(input_x, thetas, biases):\n","  \"\"\"\n","  input_x : a image of \n","  thetas : list of theta\n","  biases : list of bias\n","  \"\"\"\n","\n","  a = []\n","  num_layer = len(thetas)\n","  a.append(input_x)\n","  a_b = input_x                                     # a before \n","  for theta, bias in zip(thetas, biases):\n","    # print(\"theta's shape : \", theta.shape)      # 512, 784 etc...\n","    # print(\"bias' shape : \", bias.shape)         # 512, 1   etc...\n","    a_b = sigmoid_(np.matmul(theta, a_b) + bias)  # 512, 1 etc...\n","    # print(\"a_before's shape : \", a_b.shape)\n","    a.append(a_b)\n","\n","  # print(\"num of output is \", len(a))\n","  return a"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1nUcJUqcDnE","colab_type":"text"},"source":["- make network architecture and forwarding.\n","- set parameter's type is list and return is list of output of each layers."]},{"cell_type":"code","metadata":{"id":"fHmzfZXWjQzS","colab_type":"code","colab":{}},"source":["def network_backward(a, x, y, thetas, biases, learning_rate=1e-3, lambda_=5e-4):\n","  \n","  # get the delta\n","  deltas = []\n","  delta_before = a[-1] - y                           # 10, 1\n","  deltas.append(delta_before) \n","  # ------------------------- make reverse delta --------------------------\n","  thetas_r = thetas[::-1] # 6. 5. 4. 3. 2. 1\n","  thetas_r = thetas_r[:-1]# 6, 5, 4, 3, 2\n","\n","  # a                     # 1, 2, 3, 4, 5, 6, 7\n","  a_r = a[::-1]           # 7, 6, 5, 4, 3, 2, 1  \n","  a_r = a_r[1:-1]         # 6, 5, 4, 3, 2\n","\n","  for reverse_theta, reverse_a in zip(thetas_r, a_r):\n","    delta_before = np.matmul(reverse_theta.transpose(), delta_before) * reverse_a * (1-reverse_a)\n","    deltas.append(delta_before)\n","\n","  deltas_r = deltas[::-1]  # 2, 3, 4, 5, 6, 7\n","  new_gds = []\n","\n","  for delta_r, a_ in zip(deltas_r, a):\n","    new_gds.append(delta_r @ a_.transpose())\n","\n","  new_thetas = []\n","  new_biases = []\n","\n","  for new_gd, th, delta_r, bias in zip(new_gds, thetas, deltas_r, biases):\n","    new_thetas.append(th - learning_rate * new_gd + th * lambda_)\n","    new_biases.append(bias - learning_rate * delta_r)\n","\n","  return new_thetas, new_biases"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48s40L-UvLbw","colab_type":"text"},"source":["- make back propagation for nn by myself.\n","- if l is final layer, $\\delta^{l} = a^{l} - y$, else l is not final layer, $\\delta^{l} = (\\theta^{l-1})^{T}\\delta^{l-1} * a^{l-1} * (1 - a^{l-1})$\n","- $new gradient^{(l + 1)} = gradient^{(l)} + \\delta_{j}^{(l+1)} * (a_{j}^{(l)})^{T}$"]},{"cell_type":"code","metadata":{"id":"Wzw8SIxy1NFl","colab_type":"code","colab":{}},"source":["def criterion(out, y, thetas, biases, lambda_=5e-4):\n","  # out - shape : [10, 1]\n","  # y - shape : [10, 1] \n","  # print(\"out's shape : \", out.shape)\n","  # print(\"y's shape : \", y.shape)\n","\n","  out = out.squeeze()  # [10]\n","  y = y.squeeze()      # [10]\n","  \n","  l2_term = 0 \n","  for theta, bias in zip(thetas, biases):\n","    l2_term += np.mean(np.square(theta))\n","    l2_term += np.mean(np.square(bias))\n","\n","  if l2_term == 0:\n","    loss = np.mean(-1 * (y * np.log(out) + (1-y) * np.log(1-out)))\n","    return loss\n","\n","  l2_term *= lambda_\n","  l2_term /= 2\n","\n","  loss = np.mean(-1 * (y * np.log(out) + (1-y) * np.log(1-out))) + l2_term\n","  return loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RzphviVnO23t","colab_type":"text"},"source":["- make binary cross entropy loss for multi-label classification.\n","- add l2 normalization term."]},{"cell_type":"code","metadata":{"id":"2ewJMfRcPaYe","colab_type":"code","colab":{}},"source":["def is_same(pred, gt_label):\n","  \"\"\"\n","  pred: [10, 1]\n","  gt_label : [10, 1]\n","  \"\"\"\n","  # rint(pred.shape) # 10, 1\n","  pred = np.argmax(pred, axis=0)\n","  gt_label = np.argmax(label, axis=0)\n","\n","  return int(pred==gt_label)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CEGaj9Kfqwnb","colab_type":"text"},"source":["- make a function determine that predict label and gt label is same or not."]},{"cell_type":"markdown","metadata":{"id":"pYJ075rhy4ni","colab_type":"text"},"source":["--- \n","3. training"]},{"cell_type":"code","metadata":{"id":"w8p9inSpvOWp","colab_type":"code","colab":{}},"source":["lambda_ = 5e-6\n","\n","# training\n","th1 = np.random.normal(loc=0.0, scale=0.1, size=(512, 1500))\n","th2 = np.random.normal(loc=0.0, scale=0.1, size=(256, 512))\n","th3 = np.random.normal(loc=0.0, scale=0.1, size=(128, 256))\n","th4 = np.random.normal(loc=0.0, scale=0.1, size=(64, 128))\n","th4 = np.random.normal(loc=0.0, scale=0.1, size=(1, 64))\n","thetas = [th1, th2, th3, th4, th5]\n","\n","bias1 = np.random.normal(loc=0.0, scale=0.1, size=(512, 1))\n","bias2 = np.random.normal(loc=0.0, scale=0.1, size=(256, 1))\n","bias3 = np.random.normal(loc=0.0, scale=0.1, size=(128, 1))\n","bias4 = np.random.normal(loc=0.0, scale=0.1, size=(64, 1))\n","bias4 = np.random.normal(loc=0.0, scale=0.1, size=(1, 1))\n","biases = [bias1, bias2, bias3, bias4, bias5]\n","\n","loss_list_for_train = []\n","acc_list_for_train = []\n","\n","loss_list_for_test = []\n","acc_list_for_test = []\n","\n","# define hyperparameter for multi-label classification\n","epochs = 30\n","learning_rate = 1e-1\n","decay_steps = [15, 30]\n","\n","for epoch in range(epochs):\n","  print('\\ntraining for epoch [{}]'.format(epoch))\n","  match_cnt = 0\n","  sum_loss = 0 \n","\n","  if epoch in decay_steps:\n","    learning_rate *= 0.5\n","\n","  # training \n","  for i in range(1000):\n","    # print(i)\n","\n","    if i == 999:\n","      acc = match_cnt / (i + 1)\n","      acc *= 100\n","      acc_list_for_train.append(acc)\n","      print(\"training_acc : {:.4f}\".format(acc))\n","\n","      mean_loss = sum_loss/(i + 1)\n","      loss_list_for_train.append(mean_loss)\n","\n","    image = train_image[:, i]\n","    label = train_label[:, i]\n","\n","    image = np.expand_dims(image, axis=1) # 784 --> 784, 1\n","    label = np.expand_dims(label, axis=1) # 10 --> 10, 1\n","    a_output = network_forward(image, thetas, biases)\n","\n","    out = a_output[-1]\n","    match_cnt += is_same(out, label)\n","    loss = criterion(out, label, thetas, biases, lambda_=lambda_)\n","\n","    sum_loss += loss \n","    thetas, biases = network_backward(a_output, image, label, thetas, biases, learning_rate, lambda_)\n","    \n","  match_cnt = 0\n","  sum_loss = 0 \n","  pred_idx = []\n","  pred_label = []\n","\n","  # testing\n","  for i in range(9000):\n","      if i == 8999:\n","        acc = match_cnt / (i + 1)\n","        acc *= 100\n","        \n","        acc_list_for_test.append(acc)\n","        print(\"testing_acc : {:.4f}\".format(acc))\n","\n","        mean_loss = sum_loss/(i + 1)\n","        loss_list_for_test.append(mean_loss)\n","\n","      \n","      image = test_image[:, i]\n","      label = test_label[:, i]\n","\n","      image = np.expand_dims(image, axis=1) # 784 --> 784, 1\n","      label = np.expand_dims(label, axis=1) # 10 --> 10, 1\n","\n","      a_output = network_forward(image, thetas, biases)\n","      out = a_output[-1]\n","      match_cnt += is_same(out, label)\n","\n","      pred = np.argmax(out, axis=0)\n","      gt_label = np.argmax(label, axis=0)\n","      pred_idx.append((pred == gt_label))\n","      pred_label.append(pred)\n","\n","      loss = criterion(out, label, thetas, biases, lambda_=lambda_)\n","      sum_loss += loss\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EMyi6key4iyA","colab_type":"text"},"source":["- training until convergence at epoch 30\n","- theta and bias is applied to a normal distribution with mean 0 and standard deviation 0.1.\n","- learning rate decay is 0.5 every 15 epochs.\n","- only use numpy to implement gradient descent algorithm.\n","- network convert features like that (784 --> 256 --> 128 --> 64 --> 10)\n","- l2 norm's lambda is 5e-6."]},{"cell_type":"markdown","metadata":{"id":"x_HMQe2VX-5f","colab_type":"text"},"source":["--- \n","4. plot the loss curve"]},{"cell_type":"code","metadata":{"id":"B9gxCs7f4lr3","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","ax = plt.figure().gca()\n","# ax.set_xticks(np.arange(epoch + 1))\n","plt.plot(loss_list_for_train, c='b')\n","plt.plot(loss_list_for_test, c='r')\n","plt.legend(['training loss', 'testing loss'])\n","\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j4MG2BHZYEQY","colab_type":"text"},"source":["--- \n","5. plot the accuracy curve\n"]},{"cell_type":"code","metadata":{"id":"eZu5_c7_9J6D","colab_type":"code","colab":{}},"source":["ax = plt.figure().gca()\n","ax.set_xticks(np.arange(epoch + 1))\n","plt.plot(acc_list_for_train, c='b')\n","plt.plot(acc_list_for_test, c='r')\n","plt.legend(['training accuracy', 'testing accuracy'])\n","\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GPT4D91YLxh","colab_type":"text"},"source":["---\n","6. plot the accuracy value"]},{"cell_type":"code","metadata":{"id":"SnP2kwp5YVOx","colab_type":"code","colab":{}},"source":["print(\"final training accuracy : {:.4f}%\".format(acc_list_for_train[-1]))\n","print(\"final testing accuracy : {:.4f}%\".format(acc_list_for_test[-1]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WPHBiWG5jXcr","colab_type":"text"},"source":["--- \n","7. plot classification example."]},{"cell_type":"code","metadata":{"id":"4eV5jtXcjaE7","colab_type":"code","colab":{}},"source":["pred_idx = np.array(pred_idx).squeeze()\n","print(pred_idx)\n","pred_label = np.array(pred_label).squeeze()\n","index = pred_idx\n","\n","\n","right_index = index.astype(np.bool)\n","wrong_index = (1 - index).astype(np.bool)\n","\n","test_image_ = test_image.transpose()\n","pred_label_ = pred_label.transpose()\n","\n","right_image = test_image_[right_index]\n","right_label = pred_label_[right_index]\n","\n","right_example_image = right_image[:10] \n","right_example_label = right_label[:10] \n","\n","\n","print('\\ncorrectly classified testing images')\n","for i in range(10):\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(right_example_label[i])\n","    plt.imshow(right_example_image[i, ...].reshape((size_row, size_col)), cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()\n","\n","print('\\nmisclassified testing images')\n","\n","wrong_image = test_image_[wrong_index]\n","wrong_label = pred_label_[wrong_index]\n","\n","wrong_example_image = wrong_image[:10] \n","wrong_example_label = wrong_label[:10] \n","# print(right_example_image.shape)\n","\n","for i in range(10):\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(wrong_example_label[i])\n","    plt.imshow(wrong_example_image[i, ...].reshape((size_row, size_col)), cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ceDte3SYRr-S","colab_type":"text"},"source":["- present 10 correct, incorrect output and their label in 2x5 subfig"]},{"cell_type":"markdown","metadata":{"id":"tyuknNLD61xO","colab_type":"text"},"source":["---\n","8. testing accuracy "]},{"cell_type":"code","metadata":{"id":"cBDLncX368iQ","colab_type":"code","colab":{}},"source":["print(\"final testing accuracy : {:.4f}%\".format(acc_list_for_test[-1]))"],"execution_count":0,"outputs":[]}]}